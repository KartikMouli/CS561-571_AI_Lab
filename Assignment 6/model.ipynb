{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\karti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import string\n",
    "import operator\n",
    "from copy import deepcopy\n",
    "from math import log2\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training data...\n",
      "Training Data:\n",
      "[['DESC', 'How did serfdom develop in and then leave Russia', 9, [('How',), ('did',), ('serfdom',), ('develop',), ('in',), ('and',), ('then',), ('leave',), ('Russia',)], [('How', 'did'), ('did', 'serfdom'), ('serfdom', 'develop'), ('develop', 'in'), ('in', 'and'), ('and', 'then'), ('then', 'leave'), ('leave', 'Russia')], [('How', 'did', 'serfdom'), ('did', 'serfdom', 'develop'), ('serfdom', 'develop', 'in'), ('develop', 'in', 'and'), ('in', 'and', 'then'), ('and', 'then', 'leave'), ('then', 'leave', 'Russia')], [('How', 'WRB'), ('serfdom', 'JJ'), ('develop', 'VB'), ('leave', 'JJ'), ('Russia', 'NNP')]], ['ENTY', 'What films featured the character Popeye Doyle', 7, [('What',), ('films',), ('featured',), ('the',), ('character',), ('Popeye',), ('Doyle',)], [('What', 'films'), ('films', 'featured'), ('featured', 'the'), ('the', 'character'), ('character', 'Popeye'), ('Popeye', 'Doyle')], [('What', 'films', 'featured'), ('films', 'featured', 'the'), ('featured', 'the', 'character'), ('the', 'character', 'Popeye'), ('character', 'Popeye', 'Doyle')], [('What', 'WP'), ('films', 'VBD'), ('featured', 'JJ'), ('character', 'NN'), ('Popeye', 'NNP'), ('Doyle', 'NNP')]], ['DESC', 'How can I find a list of celebrities  real names', 11, [('How',), ('can',), ('I',), ('find',), ('a',), ('list',), ('of',), ('celebrities',), ('real',), ('names',)], [('How', 'can'), ('can', 'I'), ('I', 'find'), ('find', 'a'), ('a', 'list'), ('list', 'of'), ('of', 'celebrities'), ('celebrities', 'real'), ('real', 'names')], [('How', 'can', 'I'), ('can', 'I', 'find'), ('I', 'find', 'a'), ('find', 'a', 'list'), ('a', 'list', 'of'), ('list', 'of', 'celebrities'), ('of', 'celebrities', 'real'), ('celebrities', 'real', 'names')], [('How', 'WRB'), ('I', 'PRP'), ('find', 'VBP'), ('list', 'JJ'), ('celebrities', 'NNS'), ('real', 'JJ'), ('names', 'NNS')]], ['ENTY', 'What fowl grabs the spotlight after the Chinese Year of the Monkey', 12, [('What',), ('fowl',), ('grabs',), ('the',), ('spotlight',), ('after',), ('the',), ('Chinese',), ('Year',), ('of',), ('the',), ('Monkey',)], [('What', 'fowl'), ('fowl', 'grabs'), ('grabs', 'the'), ('the', 'spotlight'), ('spotlight', 'after'), ('after', 'the'), ('the', 'Chinese'), ('Chinese', 'Year'), ('Year', 'of'), ('of', 'the'), ('the', 'Monkey')], [('What', 'fowl', 'grabs'), ('fowl', 'grabs', 'the'), ('grabs', 'the', 'spotlight'), ('the', 'spotlight', 'after'), ('spotlight', 'after', 'the'), ('after', 'the', 'Chinese'), ('the', 'Chinese', 'Year'), ('Chinese', 'Year', 'of'), ('Year', 'of', 'the'), ('of', 'the', 'Monkey')], [('What', 'WP'), ('fowl', 'NN'), ('grabs', 'NN'), ('spotlight', 'NN'), ('Chinese', 'JJ'), ('Year', 'NNP'), ('Monkey', 'NNP')]], ['ABBR', 'What is the full form of com', 7, [('What',), ('is',), ('the',), ('full',), ('form',), ('of',), ('com',)], [('What', 'is'), ('is', 'the'), ('the', 'full'), ('full', 'form'), ('form', 'of'), ('of', 'com')], [('What', 'is', 'the'), ('is', 'the', 'full'), ('the', 'full', 'form'), ('full', 'form', 'of'), ('form', 'of', 'com')], [('What', 'WP'), ('full', 'JJ'), ('form', 'NN'), ('com', 'NN')]]]\n"
     ]
    }
   ],
   "source": [
    "def get_ngrams(data, n):\n",
    "    tokens = [token for token in data.split(\" \") if token != \"\"]\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "def get_postag(txt):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenized = sent_tokenize(txt)\n",
    "    words_list = nltk.word_tokenize(tokenized[0]) \n",
    "    words_list = [w for w in words_list if not w in stop_words]  \n",
    "    return nltk.pos_tag(words_list)\n",
    "\n",
    "def build_data(path_to_data):\n",
    "    data,uni,bi,tri,pos = [],[],[],[],[]\n",
    "    file = open(path_to_data)\n",
    "\n",
    "    for line in file:\n",
    "        line = line.split(':')\n",
    "        row = []\n",
    "        \n",
    "        _class, _question = line[0], line[1]\n",
    "        row.append(_class)\n",
    "        row.append(' '.join(_question.split(' ')[1:]).translate(str.maketrans('', '', string.punctuation)).rstrip())\n",
    "\n",
    "        length = len(row[1].split(' '))\n",
    "        row.append(length)\n",
    "\n",
    "        unigram = get_ngrams(row[1], 1)\n",
    "        row.append(unigram)\n",
    "        uni.extend(unigram)\n",
    "\n",
    "        bigram = get_ngrams(row[1], 2)\n",
    "        row.append(bigram)\n",
    "        bi.extend(bigram)\n",
    "        \n",
    "        trigram = get_ngrams(row[1], 3)\n",
    "        row.append(trigram)\n",
    "        tri.extend(trigram)\n",
    "\n",
    "        postag = get_postag(row[1])\n",
    "        row.append(postag)\n",
    "        pos.extend(postag)\n",
    "\n",
    "        # complete set of features for each text \n",
    "        data.append(row)\n",
    "\n",
    "    return data, uni, bi, tri, pos\n",
    "\n",
    "# load training data\n",
    "data, uni, bi, tri, pos = build_data('./train_data.txt')\n",
    "print('Loading Training data...')\n",
    "print('Training Data:')\n",
    "print(data[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length: 9.031548055759353\n",
      "Top features:\n",
      "\n",
      "Unigrams:\n",
      "\n",
      "[(('the',), 3589), (('What',), 3245), (('is',), 1669), (('of',), 1540), (('in',), 1131)]\n",
      "Bigrams:\n",
      "\n",
      "[(('What', 'is'), 968), (('is', 'the'), 757), (('of', 'the'), 446), (('in', 'the'), 326), (('How', 'many'), 316)]\n",
      "Trigrams:\n",
      "\n",
      "[(('What', 'is', 'the'), 551), (('What', 'is', 'a'), 151), (('What', 's', 'the'), 135), (('What', 'are', 'the'), 134), (('What', 'was', 'the'), 130)]\n",
      "Pos Counts:\n",
      "\n",
      "[(('What', 'WP'), 3245), (('How', 'WRB'), 763), (('Who', 'WP'), 559), (('many', 'JJ'), 332), (('Where', 'WRB'), 273)]\n"
     ]
    }
   ],
   "source": [
    "def top_grams(grams, top_n):\n",
    "    return Counter(grams).most_common(top_n)\n",
    "\n",
    "unigram_counts = top_grams(uni, 500)\n",
    "bigram_counts = top_grams(bi, 300)\n",
    "trigram_counts = top_grams(tri, 200)\n",
    "pos_counts = top_grams(pos, 500)\n",
    "\n",
    "avg_length = mean([row[2] for row in data])\n",
    "print('average length:',avg_length)\n",
    "\n",
    "# Displaying the top features\n",
    "print('Top features:\\n')\n",
    "print('Unigrams:\\n')\n",
    "print(unigram_counts[0:5])\n",
    "\n",
    "print('Bigrams:\\n')\n",
    "print(bigram_counts[0:5])\n",
    "\n",
    "print('Trigrams:\\n')\n",
    "print(trigram_counts[0:5])\n",
    "\n",
    "#\n",
    "print('Pos Counts:\\n')\n",
    "print(pos_counts[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "header = ['Label', 'Text', 'Length', 'Unigram', 'Bigram', 'Trigram', 'POS']\n",
    "\n",
    "class Question:\n",
    "    def __init__(self, col, value):\n",
    "        self.col = col # The column number in the header\n",
    "        self.value = value # Actual value of the object\n",
    "\n",
    "    # Matching attributes of current question with the current row\n",
    "    def match(self, example):\n",
    "        val = example[self.col]\n",
    "        if is_numeric(val):\n",
    "            return val <= self.value\n",
    "        \n",
    "        return self.value in val\n",
    "\n",
    "    # Return the string representation of the object\n",
    "    def __repr__(self):\n",
    "        condition = \"contains\"\n",
    "        return \"Does %s %s %s?\" % (\n",
    "            header[self.col], condition, str(self.value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(rows):\n",
    "    counts = {}\n",
    "    for row in rows:\n",
    "        label = row[0]\n",
    "\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        \n",
    "        counts[label] += 1\n",
    "    return counts\n",
    "\n",
    "def gini(rows):\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity\n",
    "\n",
    "def misclassifcation_error(rows):\n",
    "    counts = class_counts(rows)\n",
    "    max_prob = 0\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        if prob_of_lbl > max_prob:\n",
    "            max_prob = prob_of_lbl\n",
    "    return 1 - max_prob\n",
    "\n",
    "def entropy(rows):\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 0\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl*log2(prob_of_lbl)\n",
    "    return impurity\n",
    "\n",
    "def info_gain(left, right, current_uncertainty, func):\n",
    "    p = float(len(left))/(len(left)+len(right))\n",
    "    return current_uncertainty - p*func(left) - (1-p)*func(right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n",
      "[Does Unigram contains ('the',)?, Does Unigram contains ('What',)?, Does Unigram contains ('is',)?, Does Unigram contains ('of',)?, Does Unigram contains ('in',)?]\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "\n",
    "for x in unigram_counts:\n",
    "    questions.append(Question(3, x[0]))\n",
    "\n",
    "for x in bigram_counts:\n",
    "    questions.append(Question(4, x[0]))\n",
    "    \n",
    "for x in trigram_counts:\n",
    "    questions.append(Question(5, x[0]))\n",
    "\n",
    "for x in pos_counts:\n",
    "    questions.append(Question(6, x[0]))\n",
    "    \n",
    "questions.append(Question(2, avg_length))    \n",
    "    \n",
    "print(len(questions))\n",
    "print(questions[0:5])\n",
    "# print(questions[1500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a split of true rows and false rows for a particular question (single feature)\n",
    "def partition(rows, question):\n",
    "    rows_true = []\n",
    "    rows_false = []\n",
    "    \n",
    "    for r in rows:\n",
    "        if question.match(r):\n",
    "            rows_true.append(r)\n",
    "        else:\n",
    "            rows_false.append(r)\n",
    "    \n",
    "    return rows_true, rows_false\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows, questions, func):   \n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    current_uncertainty = func(rows)\n",
    "    \n",
    "    for q in questions:\n",
    "        rows_true, rows_false = partition(rows, q)\n",
    "        if len(rows_true) == 0 or len(rows_false) == 0:\n",
    "            continue\n",
    "        \n",
    "        gain = info_gain(rows_true, rows_false, current_uncertainty, func) # Calculating the information gain\n",
    "        # Updating best gain\n",
    "        if gain >= best_gain:\n",
    "            best_gain, best_question = gain, q\n",
    "    \n",
    "    return best_gain, best_question   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Function to form the decision tree\n",
    "# using partitioning (question list is updated periodically)\n",
    "def form_tree(rows, questions, func):\n",
    "    # Find the best gain and best question\n",
    "    gain, question = find_best_split(rows, questions, func)\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "    \n",
    "    rows_true, rows_false = partition(rows, question)\n",
    "    questions.remove(question)\n",
    "    \n",
    "    true_branch = form_tree(rows_true, questions, func)\n",
    "    false_branch = form_tree(rows_false, questions, func)\n",
    "    \n",
    "    return Decision_Node(question, true_branch, false_branch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_row(node, row):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "    \n",
    "    if node.question.match(row):\n",
    "        return classify_row(node.true_branch, row)\n",
    "    else:\n",
    "        return classify_row(node.false_branch, row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, questions, func):\n",
    "    return form_tree(data, deepcopy(questions), func)\n",
    "\n",
    "def classify(root, rows):\n",
    "    predictions = [max(classify_row(root, r).items(), key=operator.itemgetter(1))[0] for r in rows]\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_in_index(data, index):\n",
    "    l = []\n",
    "    for i in range(len(data)):\n",
    "        if i in index:\n",
    "            l.append(data[i])\n",
    "    return l\n",
    "\n",
    "def get_actual_labels(act_data):\n",
    "    act_labels = []\n",
    "    \n",
    "    for d in act_data:\n",
    "        act_labels.append(d[0])\n",
    "    \n",
    "    return act_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training...\n",
      "Training...\n",
      "Training...\n",
      "Training...\n",
      "Training...\n",
      "Training...\n",
      "Training...\n",
      "Training...\n",
      "Training...\n",
      "\n",
      "Gini Index\n",
      "Precision Score = 0.8040501395611818\n",
      "Recall Score = 0.7487842295806157\n",
      "F Score = 0.767009336109572\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "precision,recall,f_score = [],[],[]\n",
    "i = 0\n",
    "\n",
    "for trainInd, testInd in kfold.split(data):\n",
    "    train_data = get_data_in_index(data, trainInd)\n",
    "    test_data = get_data_in_index(data, testInd)\n",
    "    \n",
    "    root = train(train_data, questions, gini)\n",
    "    prediction = classify(root, test_data)\n",
    "    actual = get_actual_labels(test_data)\n",
    "    predicted = prediction\n",
    "    \n",
    "    precision.append(precision_score(actual, predicted, average='macro'))\n",
    "    recall.append(recall_score(actual, predicted, average='macro'))\n",
    "    f_score.append(f1_score(actual, predicted, average='macro'))\n",
    "     \n",
    "    print(\"Training...\")\n",
    "\n",
    "print('\\nGini Index')\n",
    "print(\"Precision Score = \"+str(mean(precision)))\n",
    "print(\"Recall Score = \"+str(mean(recall)))\n",
    "print(\"F Score = \"+str(mean(f_score)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Part 2\n",
    " - All\n",
    " - Unigram, Bigram, Trigram, POS\n",
    " - Unigram, Bigram, Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "classes = ['ABBR', 'DESC', 'ENTY', 'HUM', 'LOC', 'NUM']\n",
    "\n",
    "def getReport(train_data, test_data, uniFlag=True, biFlag=True, triFlag=True, posFlag=True, lenFlag=True, func=gini):\n",
    "    allQuestions = []\n",
    "    \n",
    "    if uniFlag:\n",
    "        for x in unigram_counts:\n",
    "            allQuestions.append(Question(3, x[0]))\n",
    "\n",
    "    if biFlag:\n",
    "        for x in bigram_counts:\n",
    "            allQuestions.append(Question(4, x[0]))\n",
    "\n",
    "    if triFlag:\n",
    "        for x in trigram_counts:\n",
    "            allQuestions.append(Question(5, x[0]))\n",
    "\n",
    "    if posFlag:\n",
    "        for x in pos_counts:\n",
    "            allQuestions.append(Question(6, x[0]))\n",
    "\n",
    "    if lenFlag:\n",
    "        allQuestions.append(Question(2, avg_length))    \n",
    "\n",
    "    print(\"No of questions = \" + str(len(allQuestions)))\n",
    "\n",
    "    print(\"Training...\")\n",
    "    root = train(train_data, allQuestions, func)\n",
    "    \n",
    "    print(\"Predicting...\")\n",
    "    prediction = classify(root, test_data)        \n",
    "    actual = get_actual_labels(test_data)\n",
    "    \n",
    "    print(\"Prediction done...\")\n",
    "    matrix = confusion_matrix(actual, prediction)\n",
    "    class_report = classification_report(actual, prediction)\n",
    "    acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    accuracy_report = dict(zip(classes, acc))\n",
    "    \n",
    "    return accuracy_report, class_report, root, prediction, actual\n",
    "\n",
    "test_data = build_data('./test_data.txt')[0]\n",
    "print(len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of questions = 1501\n",
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\karti\\Downloads\\dt\\model.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m accuracy_report, class_report, root, prediction, actual \u001b[39m=\u001b[39m getReport(train_data\u001b[39m=\u001b[39;49mdata, test_data\u001b[39m=\u001b[39;49mtest_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(accuracy_report)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(class_report)\n",
      "\u001b[1;32mc:\\Users\\karti\\Downloads\\dt\\model.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo of questions = \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(allQuestions)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m root \u001b[39m=\u001b[39m train(train_data, allQuestions, func)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPredicting...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m prediction \u001b[39m=\u001b[39m classify(root, test_data)        \n",
      "\u001b[1;32mc:\\Users\\karti\\Downloads\\dt\\model.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(data, questions, func):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m form_tree(data, deepcopy(questions), func)\n",
      "\u001b[1;32mc:\\Users\\karti\\Downloads\\dt\\model.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m questions\u001b[39m.\u001b[39mremove(question)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m true_branch \u001b[39m=\u001b[39m form_tree(rows_true, questions, func)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m false_branch \u001b[39m=\u001b[39m form_tree(rows_false, questions, func)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Decision_Node(question, true_branch, false_branch)\n",
      "\u001b[1;32mc:\\Users\\karti\\Downloads\\dt\\model.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m questions\u001b[39m.\u001b[39mremove(question)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m true_branch \u001b[39m=\u001b[39m form_tree(rows_true, questions, func)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m false_branch \u001b[39m=\u001b[39m form_tree(rows_false, questions, func)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Decision_Node(question, true_branch, false_branch)\n",
      "\u001b[1;32mc:\\Users\\karti\\Downloads\\dt\\model.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mform_tree\u001b[39m(rows, questions, func):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Find the best gain and best question\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     gain, question \u001b[39m=\u001b[39m find_best_split(rows, questions, func)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m gain \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m Leaf(rows)\n",
      "\u001b[1;32mc:\\Users\\karti\\Downloads\\dt\\model.ipynb Cell 18\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m current_uncertainty \u001b[39m=\u001b[39m func(rows)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m questions:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     rows_true, rows_false \u001b[39m=\u001b[39m partition(rows, q)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(rows_true) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(rows_false) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\karti\\Downloads\\dt\\model.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         rows_true\u001b[39m.\u001b[39mappend(r)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         rows_false\u001b[39m.\u001b[39mappend(r)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/Downloads/dt/model.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rows_true, rows_false\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data, func=entropy)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data, func=misclassifcation_error)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data, lenFlag=False)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data, lenFlag=False, func=entropy)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data, lenFlag=False, func=misclassifcation_error)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data, lenFlag=False, posFlag=False)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data, lenFlag=False, posFlag=False, func=entropy)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report, class_report, root, prediction, actual = getReport(train_data=data, test_data=test_data, lenFlag=False, posFlag=False, func=misclassifcation_error)\n",
    "print(accuracy_report)\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrong_prediction(prediction, actual, dataset):\n",
    "    data_list = [dataset[i] for i in range(len(prediction)) if prediction[i] != actual[i]]\n",
    "    return data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , class_matrix, root_gini, prediction_gini, actual_gini  = getReport(train_data=data, test_data=test_data)\n",
    "wrong_data = get_wrong_prediction(prediction_gini, actual_gini, test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the wrong data length\n",
    "print('Len of wrong data for gini', len(wrong_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , class_matrix, root_entropy, prediction_entropy, actual_entropy  = getReport(train_data=data, test_data=wrong_data, func=entropy)\n",
    "wrong_data_en = get_wrong_prediction(prediction_entropy, actual_entropy, wrong_data)\n",
    "print('Len of wrong data for entropy is', len(wrong_data_en))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , class_matrix, root_mis, prediction_mis, actual_mis  = getReport(train_data=data, test_data=wrong_data, func=misclassifcation_error)\n",
    "wrong_data_mis = get_wrong_prediction(prediction_entropy, actual_entropy, wrong_data)\n",
    "print('Len of wrong data for misclassifcation_error is', len(wrong_data_mis))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Entropy correctly classifies', (len(wrong_data) - len(wrong_data_en)), 'as compared to GINI metric')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Misclassification error correctly classifies', (len(wrong_data) - len(wrong_data_mis)), 'as compared to GINI metric')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
